{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54668272",
   "metadata": {},
   "source": [
    "# (12) Vector Autoregressive Model with Lasso Estimation (VAR_Lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5471924b",
   "metadata": {},
   "source": [
    "A vector autoregressive (VAR) model with $p$ lags is defined by \n",
    "\n",
    "$$\n",
    "Y_{t} = c + \\sum_{i=1}^{p} \\Phi_{i}Y_{t-i} + e_{t}.\n",
    "$$\n",
    "\n",
    "where $Y_{t}$ is an $8 \\times 1$ vector of endogenous variables, $c$ is an $8 \\times 1 $ vector of equation constants, $\\Phi_{i}$ is an $8 \\times 8$ matrix of coefficients to be determined during model estimation, and $e_{t}$ is an $8 \\times 1$ vector of forecast errors. \n",
    "\n",
    "Lasso estimation is applied to every equation within the VAR framework. Lasso estimation works by adding a penalty term designed to minimize the sum of absolute coefficients. Therefore, the coefficients of less important predictors are pushed to zero. In other words, lasso estimation performs variables selection. However, it does not work well in cases of correlated predictors.    \n",
    "\n",
    "$$\n",
    "L(a_{1},...,a_{n_{a}}) = \\sum_{t}(Y_{t+1} - Y_{t+1|t})^{2} + \\lambda_{1}\\sum_{j=1}^{n_{a}}|a_{j}|\n",
    "$$\n",
    "\n",
    "The optimal lag length of $p$ is set to a length long enough to return white noise residuals in each VAR equation. A reasonable penalty parameter ($\\lambda_{1}$) is set using validation set root mean squared error (RMSE) minimization that is designed to minimize the forecast errors of the target series only. Therefore, only one pentalty parameter is set within the entire system AND NOT a different penalty parameter for each equation. The following code reestimates the VAR model each period using walk foreword cross-validation with a fixed lag length over the validation set. Model validation is carried out using an 80-20 split. The initial training model is estimated on the first 80% of the training data. The training model weights are updated after each peiord. Therefore, model weights are always updated to reflect the most recent information. Walk foreword cross-validation is carried out on the remaining 20% of the in-sample set. Each $h$-step ahead forecast is produced using linear model iteration. In the codes below, the phrase \"test\" actually references the “validation” set AND NOT an out-of-sample test set. \n",
    "\n",
    "The first block of code defines two functions. The DataSpace function takes in the data (both the target series and the remaining predictors) with the number of lags to use during estimation (lags) and returns a dataframe containing the current periods predictors (current_data), a dataframe containing the lagged data (lagged_data), the number of observations in the training set (train_size), the number of observations in the test set (test_size), and the size of the information set (features). The MODEL function takes in seven arguments. The current data to be forecasted is defined using the current_data argument. The dataframe containing the correct number of lags is defined using the lagged_data argument. The number of observations in the training set using the train_size argument. The number of observations in the test set is set using the test_set argument. The number of variables in variable space is defined by the features argument. The regularization parameter is set using the penalty argument. Lastly, the number of forecast horizons is defined by step_size. The output of the MODEL function is designed to return the training and validation set RMSE values during regularization parameter grid searching. After a reasonable regularization parameter is set into the model, the MODEL function will then return the training and validation set predicted values. The first block of code defines a region to grid search in order to identify a reasonable regularization parameter. The second block of code sets the reasonable regularization parameter into the model and returns the forecasts.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cb4bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Library:\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Function to Create VAR Feature Space:\n",
    "def DataSpace(data, p = 36):\n",
    "    # Inital Training & Test Set Sizes:\n",
    "    train_size = int(data.shape[0]*0.8 - p)\n",
    "    test_size = data.shape[0] - train_size - p\n",
    "    features = data.shape[1]\n",
    "    # Compute Lagged DataFrame:\n",
    "    names = data.columns\n",
    "    for i in range(1,p+1,1):\n",
    "        for j in range(features):\n",
    "            names = np.append(names, names[j]+'_L'+str(i))\n",
    "            data[names[j]+'_L'+str(i)] = data[names[j]].shift(i)\n",
    "    data = data.dropna()\n",
    "    # Break in to Current and Lagged Space:\n",
    "    current_data = data.iloc[:, 0:features]\n",
    "    lagged_data = data.iloc[:, features:]\n",
    "    return current_data, lagged_data, train_size, test_size, features\n",
    "# Function to Fit Model using Walk Foreward Cross-Validation:\n",
    "def MODEL(current_data, lagged_data, train_size, test_size, features, penalty = 1.0, step_size = 1):\n",
    "    # Extracting Data:\n",
    "    index_values = current_data.index.values\n",
    "    # Storage & Model Estimation:\n",
    "    test_pred = []\n",
    "    name = 'VAR-Type Lasso Regression'\n",
    "    print('-'*len(name))\n",
    "    print(name)\n",
    "    print('-'*len(name))\n",
    "    print('Penalty Parameter: ', penalty)\n",
    "    for t in range(test_size - step_size + 1):\n",
    "        # Tracking Convergence:\n",
    "        print('Test Set Walk Foreward: Iteration '+str(t+1))\n",
    "        # Define Walk Foreward Training Sets:\n",
    "        feature_space_train = lagged_data.values[:train_size+t, :]\n",
    "        RHP_train = current_data.values[:train_size+t, 0]\n",
    "        DSPIC96_train = current_data.values[:train_size+t, 1]\n",
    "        CPIAUCSL_train = current_data.values[:train_size+t, 2]\n",
    "        REALSP500_train = current_data.values[:train_size+t, 3]\n",
    "        CUSR0000SEHA_train = current_data.values[:train_size+t, 4]\n",
    "        UNRATE_train = current_data.values[:train_size+t, 5]\n",
    "        RMORTGAGE_train = current_data.values[:train_size+t, 6]\n",
    "        TWEXAFEGSMTHx_train = current_data.values[:train_size+t, 7]\n",
    "        # Define Walk Foreward Test Sets:\n",
    "        feature_space_test = lagged_data.values[train_size+t:, :]\n",
    "        RHP_test = current_data.values[train_size+t:, 0]\n",
    "        DSPIC96_test = current_data.values[train_size+t:, 1]\n",
    "        CPIAUCSL_test = current_data.values[train_size+t:, 2]\n",
    "        REALSP500_test = current_data.values[train_size+t:, 3]\n",
    "        CUSR0000SEHA_test = current_data.values[train_size+t:, 4]\n",
    "        UNRATE_test = current_data.values[train_size+t:, 5]\n",
    "        RMORTGAGE_test = current_data.values[train_size+t:, 6]\n",
    "        TWEXAFEGSMTHx_test = current_data.values[train_size+t:, 7]\n",
    "        # Fit Model to Training Set: RHP Equation \n",
    "        RHP_model = Lasso(alpha = penalty, random_state = 1)\n",
    "        RHP_model.fit(X = feature_space_train, y = RHP_train)\n",
    "        # Fit Model to Training Set: DSPIC96 Equation\n",
    "        DSPIC96_model = Lasso(alpha = penalty, random_state = 1)\n",
    "        DSPIC96_model.fit(X = feature_space_train, y = DSPIC96_train)\n",
    "        # Fit Model to Training Set: CPIAUCSL Equation\n",
    "        CPIAUCSL_model = Lasso(alpha = penalty, random_state = 1)\n",
    "        CPIAUCSL_model.fit(X = feature_space_train, y = CPIAUCSL_train)\n",
    "        # Fit Model to Training Set: REALSP500 Equation\n",
    "        REALSP500_model = Lasso(alpha = penalty, random_state = 1)\n",
    "        REALSP500_model.fit(X = feature_space_train, y = REALSP500_train)\n",
    "        # Fit Model to Training Set: CUSR0000SEHA Equation\n",
    "        CUSR0000SEHA_model = Lasso(alpha = penalty, random_state = 1)\n",
    "        CUSR0000SEHA_model.fit(X = feature_space_train, y = CUSR0000SEHA_train)\n",
    "        # Fit Model to Training Set: UNRATE Equation\n",
    "        UNRATE_model = Lasso(alpha = penalty, random_state = 1)\n",
    "        UNRATE_model.fit(X = feature_space_train, y = UNRATE_train)\n",
    "        # Fit Model to Training Set: RMORTGAGE Equation\n",
    "        RMORTGAGE_model = Lasso(alpha = penalty, random_state = 1)\n",
    "        RMORTGAGE_model.fit(X = feature_space_train, y = RMORTGAGE_train)\n",
    "        # Fit Model to Training Set: TWEXAFEGSMTHx Equation\n",
    "        TWEXAFEGSMTHx_model = Lasso(alpha = penalty, random_state = 1)\n",
    "        TWEXAFEGSMTHx_model.fit(X = feature_space_train, y = TWEXAFEGSMTHx_train) \n",
    "        # Forecast Storage:\n",
    "        forecast_storage = lagged_data.values[train_size+t,:]\n",
    "        RHP_horizons = []\n",
    "        DSPIC96_horizons = []\n",
    "        CPIAUCSL_horizons = []\n",
    "        REALSP500_horizons =[]\n",
    "        CUSR0000SEHA_horizons = []\n",
    "        UNRATE_horizons = []\n",
    "        RMORTGAGE_horizons = []\n",
    "        TWEXAFEGSMTHx_horizons = []\n",
    "        for h in range(step_size):\n",
    "            # Storing Iterative Forecasts:\n",
    "            RHP_horizons = np.append(RHP_horizons, RHP_model.predict(X = forecast_storage[0:lagged_data.shape[1]].reshape(1,lagged_data.shape[1])))\n",
    "            DSPIC96_horizons = np.append(DSPIC96_horizons, DSPIC96_model.predict(X = forecast_storage[0:lagged_data.shape[1]].reshape(1,lagged_data.shape[1])))\n",
    "            CPIAUCSL_horizons = np.append(CPIAUCSL_horizons, CPIAUCSL_model.predict(X = forecast_storage[0:lagged_data.shape[1]].reshape(1,lagged_data.shape[1])))\n",
    "            REALSP500_horizons = np.append(REALSP500_horizons, REALSP500_model.predict(X = forecast_storage[0:lagged_data.shape[1]].reshape(1,lagged_data.shape[1])))\n",
    "            CUSR0000SEHA_horizons = np.append(CUSR0000SEHA_horizons, CUSR0000SEHA_model.predict(X = forecast_storage[0:lagged_data.shape[1]].reshape(1,lagged_data.shape[1])))\n",
    "            UNRATE_horizons = np.append(UNRATE_horizons, UNRATE_model.predict(X = forecast_storage[0:lagged_data.shape[1]].reshape(1,lagged_data.shape[1])))\n",
    "            RMORTGAGE_horizons = np.append(RMORTGAGE_horizons, RMORTGAGE_model.predict(X = forecast_storage[0:lagged_data.shape[1]].reshape(1,lagged_data.shape[1])))\n",
    "            TWEXAFEGSMTHx_horizons = np.append(TWEXAFEGSMTHx_horizons, TWEXAFEGSMTHx_model.predict(X = forecast_storage[0:lagged_data.shape[1]].reshape(1,lagged_data.shape[1])))\n",
    "            # Updating Predictor Space:\n",
    "            forecast_storage = np.insert(forecast_storage, 0, RHP_horizons[h])\n",
    "            forecast_storage = np.insert(forecast_storage, 1, DSPIC96_horizons[h])\n",
    "            forecast_storage = np.insert(forecast_storage, 2, CPIAUCSL_horizons[h])\n",
    "            forecast_storage = np.insert(forecast_storage, 3, REALSP500_horizons[h])\n",
    "            forecast_storage = np.insert(forecast_storage, 4, CUSR0000SEHA_horizons[h])\n",
    "            forecast_storage = np.insert(forecast_storage, 5, UNRATE_horizons[h])\n",
    "            forecast_storage = np.insert(forecast_storage, 6, RMORTGAGE_horizons[h])\n",
    "            forecast_storage = np.insert(forecast_storage, 7, TWEXAFEGSMTHx_horizons[h])\n",
    "        # Store Forecasted Values:\n",
    "        test_pred = np.append(test_pred, RHP_horizons[step_size - 1])\n",
    "        # Store Training Predictions:\n",
    "        if t == 0:\n",
    "            train_pred = RHP_model.predict(X = feature_space_train)\n",
    "            train_RMSE = np.sqrt(mean_squared_error(RHP_train, train_pred))\n",
    "    # Model Evaluation:\n",
    "    test_RMSE = np.sqrt(mean_squared_error(current_data.values[train_size + step_size - 1:, 0], test_pred))\n",
    "    return train_RMSE, test_RMSE\n",
    "# Setting Seed:\n",
    "np.random.seed(12345)\n",
    "# Load Data:\n",
    "data = read_csv('Milunovich_National.csv', header = 0, index_col = 0, parse_dates = True)\n",
    "data.index = pd.DatetimeIndex(data.index.values, freq = \"MS\")\n",
    "# Create VAR-Type Feature Space:\n",
    "AR_Lags = 36\n",
    "current_data, lagged_data, train_size, test_size, features = DataSpace(data, p = AR_Lags)\n",
    "# Storage for Results & Hyperparameters:\n",
    "Results = pd.DataFrame(columns = ['Lags', 'Penalty', 'Train_RMSE', 'Test_RMSE'])\n",
    "lambda_1 = np.arange(0.001,10.001,0.001)\n",
    "horizons = 1\n",
    "for lam in lambda_1:\n",
    "    try:\n",
    "        train_RMSE, test_RMSE = MODEL(current_data, lagged_data, train_size, test_size, features, penalty = lam, step_size = horizons)\n",
    "        model_performance = {'Lags':AR_Lags, 'Penalty':lam, 'Train_RMSE':train_RMSE, 'Test_RMSE':test_RMSE}\n",
    "        Results = Results.append(model_performance, ignore_index = True)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d2f753",
   "metadata": {},
   "source": [
    "The second block of code reestimates the top performing model after determining a reasonable regularization parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22367fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Library:\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Function to Create VAR Feature Space:\n",
    "def DataSpace(data, p = 36):\n",
    "    # Inital Training & Test Set Sizes:\n",
    "    train_size = int(data.shape[0]*0.8 - p)\n",
    "    test_size = data.shape[0] - train_size - p\n",
    "    features = data.shape[1]\n",
    "    # Compute Lagged DataFrame:\n",
    "    names = data.columns\n",
    "    for i in range(1,p+1,1):\n",
    "        for j in range(features):\n",
    "            names = np.append(names, names[j]+'_L'+str(i))\n",
    "            data[names[j]+'_L'+str(i)] = data[names[j]].shift(i)\n",
    "    data = data.dropna()\n",
    "    # Break in to Current and Lagged Space:\n",
    "    current_data = data.iloc[:, 0:features]\n",
    "    lagged_data = data.iloc[:, features:]\n",
    "    return current_data, lagged_data, train_size, test_size, features\n",
    "# Function to Fit Model using Walk Foreward Cross-Validation:\n",
    "def MODEL(current_data, lagged_data, train_size, test_size, features, penalty = 1.0, step_size = 1):\n",
    "    # Extracting Data:\n",
    "    index_values = current_data.index.values\n",
    "    # Storage & Model Estimation:\n",
    "    test_pred = []\n",
    "    name = 'VAR-Type Lasso Regression'\n",
    "    print('-'*len(name))\n",
    "    print(name)\n",
    "    print('-'*len(name))\n",
    "    print('Penalty Parameter: ', penalty)\n",
    "    for t in range(test_size - step_size + 1):\n",
    "        # Tracking Convergence:\n",
    "        print('Test Set Walk Foreward: Iteration '+str(t+1))\n",
    "        # Define Walk Foreward Training Sets:\n",
    "        feature_space_train = lagged_data.values[:train_size+t, :]\n",
    "        RHP_train = current_data.values[:train_size+t, 0]\n",
    "        DSPIC96_train = current_data.values[:train_size+t, 1]\n",
    "        CPIAUCSL_train = current_data.values[:train_size+t, 2]\n",
    "        REALSP500_train = current_data.values[:train_size+t, 3]\n",
    "        CUSR0000SEHA_train = current_data.values[:train_size+t, 4]\n",
    "        UNRATE_train = current_data.values[:train_size+t, 5]\n",
    "        RMORTGAGE_train = current_data.values[:train_size+t, 6]\n",
    "        TWEXAFEGSMTHx_train = current_data.values[:train_size+t, 7]\n",
    "        # Define Walk Foreward Test Sets:\n",
    "        feature_space_test = lagged_data.values[train_size+t:, :]\n",
    "        RHP_test = current_data.values[train_size+t:, 0]\n",
    "        DSPIC96_test = current_data.values[train_size+t:, 1]\n",
    "        CPIAUCSL_test = current_data.values[train_size+t:, 2]\n",
    "        REALSP500_test = current_data.values[train_size+t:, 3]\n",
    "        CUSR0000SEHA_test = current_data.values[train_size+t:, 4]\n",
    "        UNRATE_test = current_data.values[train_size+t:, 5]\n",
    "        RMORTGAGE_test = current_data.values[train_size+t:, 6]\n",
    "        TWEXAFEGSMTHx_test = current_data.values[train_size+t:, 7]\n",
    "        # Fit Model to Training Set: RHP Equation \n",
    "        RHP_model = Lasso(alpha = penalty, random_state = 1)\n",
    "        RHP_model.fit(X = feature_space_train, y = RHP_train)\n",
    "        # Fit Model to Training Set: DSPIC96 Equation\n",
    "        DSPIC96_model = Lasso(alpha = penalty, random_state = 1)\n",
    "        DSPIC96_model.fit(X = feature_space_train, y = DSPIC96_train)\n",
    "        # Fit Model to Training Set: CPIAUCSL Equation\n",
    "        CPIAUCSL_model = Lasso(alpha = penalty, random_state = 1)\n",
    "        CPIAUCSL_model.fit(X = feature_space_train, y = CPIAUCSL_train)\n",
    "        # Fit Model to Training Set: REALSP500 Equation\n",
    "        REALSP500_model = Lasso(alpha = penalty, random_state = 1)\n",
    "        REALSP500_model.fit(X = feature_space_train, y = REALSP500_train)\n",
    "        # Fit Model to Training Set: CUSR0000SEHA Equation\n",
    "        CUSR0000SEHA_model = Lasso(alpha = penalty, random_state = 1)\n",
    "        CUSR0000SEHA_model.fit(X = feature_space_train, y = CUSR0000SEHA_train)\n",
    "        # Fit Model to Training Set: UNRATE Equation\n",
    "        UNRATE_model = Lasso(alpha = penalty, random_state = 1)\n",
    "        UNRATE_model.fit(X = feature_space_train, y = UNRATE_train)\n",
    "        # Fit Model to Training Set: RMORTGAGE Equation\n",
    "        RMORTGAGE_model = Lasso(alpha = penalty, random_state = 1)\n",
    "        RMORTGAGE_model.fit(X = feature_space_train, y = RMORTGAGE_train)\n",
    "        # Fit Model to Training Set: TWEXAFEGSMTHx Equation\n",
    "        TWEXAFEGSMTHx_model = Lasso(alpha = penalty, random_state = 1)\n",
    "        TWEXAFEGSMTHx_model.fit(X = feature_space_train, y = TWEXAFEGSMTHx_train) \n",
    "        # Forecast Storage:\n",
    "        forecast_storage = lagged_data.values[train_size+t,:]\n",
    "        RHP_horizons = []\n",
    "        DSPIC96_horizons = []\n",
    "        CPIAUCSL_horizons = []\n",
    "        REALSP500_horizons =[]\n",
    "        CUSR0000SEHA_horizons = []\n",
    "        UNRATE_horizons = []\n",
    "        RMORTGAGE_horizons = []\n",
    "        TWEXAFEGSMTHx_horizons = []\n",
    "        for h in range(step_size):\n",
    "            # Storing Iterative Forecasts:\n",
    "            RHP_horizons = np.append(RHP_horizons, RHP_model.predict(X = forecast_storage[0:lagged_data.shape[1]].reshape(1,lagged_data.shape[1])))\n",
    "            DSPIC96_horizons = np.append(DSPIC96_horizons, DSPIC96_model.predict(X = forecast_storage[0:lagged_data.shape[1]].reshape(1,lagged_data.shape[1])))\n",
    "            CPIAUCSL_horizons = np.append(CPIAUCSL_horizons, CPIAUCSL_model.predict(X = forecast_storage[0:lagged_data.shape[1]].reshape(1,lagged_data.shape[1])))\n",
    "            REALSP500_horizons = np.append(REALSP500_horizons, REALSP500_model.predict(X = forecast_storage[0:lagged_data.shape[1]].reshape(1,lagged_data.shape[1])))\n",
    "            CUSR0000SEHA_horizons = np.append(CUSR0000SEHA_horizons, CUSR0000SEHA_model.predict(X = forecast_storage[0:lagged_data.shape[1]].reshape(1,lagged_data.shape[1])))\n",
    "            UNRATE_horizons = np.append(UNRATE_horizons, UNRATE_model.predict(X = forecast_storage[0:lagged_data.shape[1]].reshape(1,lagged_data.shape[1])))\n",
    "            RMORTGAGE_horizons = np.append(RMORTGAGE_horizons, RMORTGAGE_model.predict(X = forecast_storage[0:lagged_data.shape[1]].reshape(1,lagged_data.shape[1])))\n",
    "            TWEXAFEGSMTHx_horizons = np.append(TWEXAFEGSMTHx_horizons, TWEXAFEGSMTHx_model.predict(X = forecast_storage[0:lagged_data.shape[1]].reshape(1,lagged_data.shape[1])))\n",
    "            # Updating Predictor Space:\n",
    "            forecast_storage = np.insert(forecast_storage, 0, RHP_horizons[h])\n",
    "            forecast_storage = np.insert(forecast_storage, 1, DSPIC96_horizons[h])\n",
    "            forecast_storage = np.insert(forecast_storage, 2, CPIAUCSL_horizons[h])\n",
    "            forecast_storage = np.insert(forecast_storage, 3, REALSP500_horizons[h])\n",
    "            forecast_storage = np.insert(forecast_storage, 4, CUSR0000SEHA_horizons[h])\n",
    "            forecast_storage = np.insert(forecast_storage, 5, UNRATE_horizons[h])\n",
    "            forecast_storage = np.insert(forecast_storage, 6, RMORTGAGE_horizons[h])\n",
    "            forecast_storage = np.insert(forecast_storage, 7, TWEXAFEGSMTHx_horizons[h])\n",
    "        # Store Forecasted Values:\n",
    "        test_pred = np.append(test_pred, RHP_horizons[step_size - 1])\n",
    "        # Store Training Predictions:\n",
    "        if t == 0:\n",
    "            train_pred = RHP_model.predict(X = feature_space_train)\n",
    "            train_RMSE = np.sqrt(mean_squared_error(RHP_train, train_pred))\n",
    "    # Model Evaluation:\n",
    "    test_RMSE = np.sqrt(mean_squared_error(current_data.values[train_size + step_size - 1:, 0], test_pred))\n",
    "    train_pred = pd.DataFrame(train_pred, index = index_values[:train_size], columns = ['train_pred'])\n",
    "    test_pred = pd.DataFrame(test_pred, index = index_values[train_size + step_size - 1:], columns = ['test_pred'])\n",
    "    return train_RMSE, test_RMSE, train_pred, test_pred \n",
    "# Setting Seed:\n",
    "np.random.seed(12345)\n",
    "# Load Data:\n",
    "data = read_csv('Milunovich_National.csv', header = 0, index_col = 0, parse_dates = True)\n",
    "data.index = pd.DatetimeIndex(data.index.values, freq = \"MS\")\n",
    "# Create VAR-Type Feature Space:\n",
    "AR_Lags = Results.sort_values(by = 'Test_RMSE', ascending = True).iloc[0,0]\n",
    "current_data, lagged_data, train_size, test_size, features = DataSpace(data, p = AR_Lags)\n",
    "target_series = current_data.iloc[:,0]\n",
    "# Storage for Results & Hyperparameters:\n",
    "lambda_1 = Results.sort_values(by = 'Test_RMSE', ascending = True).iloc[0,1]\n",
    "horizons = 1\n",
    "# Evaluate Model:\n",
    "train_RMSE, test_RMSE, train_pred, test_pred = MODEL(current_data, lagged_data, train_size, test_size, features, penalty = lambda_1, step_size = horizons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198dea90",
   "metadata": {},
   "source": [
    "The third block presents and graphs the stored output from the MODEL function. The MODEL above is fit to housing price data in order to forecast real housing price growth rates at the U.S. national level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335f6296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model: Growth Rates\n",
    "print('-----------------------------')\n",
    "print('National Housing Price Series')\n",
    "print('-----------------------------')\n",
    "print('Data Type: Growth Rates')\n",
    "print('Model Type: VAR-Type Lasso Regression')\n",
    "print('Penalty Hyperparameter: ', lambda_1)\n",
    "print('Train RMSE: %.3f' % (train_RMSE))\n",
    "print('Test RMSE: %.3f' % (test_RMSE))\n",
    "# Plot Forecast: Growth Rates\n",
    "sns.set_theme(style = 'whitegrid')\n",
    "pyplot.figure(figsize = (12,6))\n",
    "pyplot.plot(target_series, label = 'Observed')\n",
    "pyplot.plot(train_pred, label = 'VAR_Lasso: Train')\n",
    "pyplot.plot(test_pred, label = 'VAR_Lasso: Test')\n",
    "pyplot.xlabel('Date')\n",
    "pyplot.ylabel('Growth Rate')\n",
    "pyplot.title('Real Housing Price Series (National)')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9416c968",
   "metadata": {},
   "source": [
    "The fourth block of code is used to analyze the forecast errors for stationarity. The forecast errors are computed, plotted, and distributed. Lastly, the autocorrelation function (ACF) is plotted and the Augmented Dickey-Fuller (ADF) unit root test is carried out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f71e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Library:\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "# Compute Model Residuals:\n",
    "Error = pd.concat([target_series,train_pred], axis = 1)\n",
    "Error = Error.dropna()\n",
    "Error['Resids'] = Error.iloc[:,0] - Error.iloc[:,1]\n",
    "# Plot Residuals:\n",
    "sns.set_theme(style = 'whitegrid')\n",
    "pyplot.figure(figsize = (16,4))\n",
    "pyplot.subplot(1,2,1)\n",
    "pyplot.plot(Error['Resids'])\n",
    "pyplot.xlabel('Date')\n",
    "pyplot.title('Residual Series')\n",
    "pyplot.subplot(1,2,2)\n",
    "pyplot.hist(Error['Resids'], bins = 20)\n",
    "pyplot.title('Residual Distribution')\n",
    "pyplot.tight_layout()\n",
    "pyplot.show()\n",
    "# Plot Autocorelation Function (ACF):\n",
    "sns.set_theme(style = 'whitegrid')\n",
    "fig, ax = pyplot.subplots(figsize=(8,4))\n",
    "plot_acf(Error['Resids'], title = 'Residual ACF', lags = 36, ax = ax)\n",
    "pyplot.show()\n",
    "# ADF Test: Non-Stationary v. Stationary\n",
    "ADF_Test = adfuller(Error['Resids'])\n",
    "print('----------------------')\n",
    "print('  ADF Unit-Root Test  ')\n",
    "print('----------------------')\n",
    "print('Test Statistic: %.3f' % (ADF_Test[0]))\n",
    "print('P-Value: %.3f' % (ADF_Test[1]))\n",
    "print('Critical Values:')\n",
    "for key, value in ADF_Test[4].items():\n",
    "    print('%s: %.3f' % (key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe8b8b9",
   "metadata": {},
   "source": [
    "The last block of code loads in the previous .csv files \"National_Train_Growth_One\" and \"National_Test_Growth_One\" that contain the stored forecasted values. The storage files are then augmented to include the predicted values from the current algorithm in order to estimate the forecast combinations, produce the final \"top performing\" model plots, and carry out the final comparison tests for predictive accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f30f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Forecast Tables: \n",
    "train_forecasts = read_csv('National_Train_Growth_One.csv', header = 0, index_col = 0, parse_dates = True)\n",
    "train_forecasts.index = pd.DatetimeIndex(train_forecasts.index.values, freq = \"MS\")\n",
    "test_forecasts = read_csv('National_Test_Growth_One.csv', header = 0, index_col = 0, parse_dates = True)\n",
    "test_forecasts.index = pd.DatetimeIndex(test_forecasts.index.values, freq = \"MS\")\n",
    "# Add New Forecast Model:\n",
    "train_forecasts['VAR_Lasso'] = train_pred\n",
    "test_forecasts['VAR_Lasso'] = test_pred\n",
    "# Save Forecast:\n",
    "pd.DataFrame(train_forecasts).to_csv('National_Train_Growth_One.csv')\n",
    "pd.DataFrame(test_forecasts).to_csv('National_Test_Growth_One.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "629633bf",
   "metadata": {},
   "source": [
    "# (3) Autoregressive (AR) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b486fe7",
   "metadata": {},
   "source": [
    "A autoregressive (AR) model with $p$ lags is defined by \n",
    "\n",
    "$$\n",
    "Y_{t} = c + \\sum_{i=1}^{p} a_{i}Y_{t-i} + e_{t}.\n",
    "$$\n",
    "\n",
    "Estimation is carried out by minimizing the forecast errors via an ordinary least squares (OLS)\n",
    "\n",
    "$$\n",
    "L(a_{1},...,a_{p}) = \\sum_{t}(Y_{t+1} - f_{t+1|t})^{2}.\n",
    "$$\n",
    "\n",
    "Here, $Y_{t}$ represents a growth rates series to be forecasted and $a_{i}$ indicates the coefficients to be determined through model estimation. The optimal lag length of $p$ is set using validation set root mean squared error (RMSE) minimization. The following code reestimates the AR model each period using walk foreword cross-validation with a fixed lag length over the validation set. Model validation is carried out using an 80-20 split. The initial training model is estimated on the first 80% of the training data. The training model weights are updated after each peiord. Therefore, model weights are always updated to reflect the most recent information. Walk foreword cross-validation is carried out on the remaining 20% of the in-sample set. Each $h$-step ahead forecast is produced using linear model iteration. In the codes below, the phrase \"test\" actually references the “validation” set AND NOT an out-of-sample test set. \n",
    "\n",
    "The first block of code defines a function (MODEL) that takes in five arguments. The univariate series to be forecasted is defined using the data argument. The argument p defines the number of autoregressive (AR) lags (AR_Lags) to set in an ARIMA model. The q defines the number of moving average (MA) lags (MA_Lags) to set in an ARIMA model. The trend argument determines whether the model is estimated with a constant (c) or not (n) via the Const command. The number of multistep ahead forecasts are set using the step_size argument through horizons. The output of MODEL allows the researcher to analyze the number of observations in the training set (train_size), the training set predictions (train_pred), the test set predictions (test_pred), the training root mean squared error value (train_RMSE), the test set root mean squared error value (test_RMSE), the AIC, and BIC values. The evaluation metrics are stored in the Results DataFrame, which is used to determine the top-performing model via lag order selection. Therefore, the first block carries out our grid search methodology using walk-foreward cross-validation with the optimal lag length determined by validation set RMSE minimization.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ec6e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Library:\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Function to Fit Model using Walk Foreward Cross-Validation:\n",
    "def MODEL(data, p = 0, q = 0, step_size = 1, trend = 'n'):\n",
    "    # Extracting Data:\n",
    "    index_values = data.index.values\n",
    "    data = data.values\n",
    "    # Inital Training & Test Set Sizes:\n",
    "    train_size = int(len(data)*0.8)\n",
    "    test_size = len(data)-train_size\n",
    "    # Storage for Growth Forecasts:\n",
    "    test_pred = []\n",
    "    name = 'AR('+str(p)+') Model'\n",
    "    print('-'*len(name))\n",
    "    print(name)\n",
    "    print('-'*len(name))\n",
    "    for t in range(test_size-step_size+1):\n",
    "        # Walk Foreward Training Set:\n",
    "        train_set = data[:train_size+t]\n",
    "        # Walk Foreward Test Set:\n",
    "        test_set = data[train_size+t:]\n",
    "        # Tracking Convergence:\n",
    "        print('Test Set Walk Foreward: Iteration '+str(t+1))\n",
    "        # Fit Training Model:\n",
    "        model = SARIMAX(train_set, order = (p,0,q), trend = trend, enforce_stationarity = False, enforce_invertibility = False)\n",
    "        model_fit = model.fit(method = 'bfgs', maxiter = 10000)\n",
    "        # Original Training Model: No Data Leakage\n",
    "        if t == 0:\n",
    "            train_pred = model_fit.predict().reshape((train_size,1))\n",
    "            AIC = model_fit.aic\n",
    "            BIC = model_fit.bic\n",
    "        # N-Step Ahead Forecast:\n",
    "        test_yhat = model_fit.forecast(steps = step_size)\n",
    "        test_pred = np.append(test_pred, test_yhat[step_size-1])\n",
    "    # Model Evaluation:\n",
    "    train_RMSE = np.sqrt(mean_squared_error(data[:train_size], train_pred))\n",
    "    test_RMSE = np.sqrt(mean_squared_error(data[train_size+step_size-1:], test_pred))\n",
    "    return train_RMSE, test_RMSE, AIC, BIC\n",
    "# Setting Seed:\n",
    "np.random.seed(12345)\n",
    "# Load in Data & Set Index Frequency: DataFrame \n",
    "univariate_data = read_csv('Univariate_Data.csv', header = 0, index_col = 0, parse_dates = True)\n",
    "univariate_data.index = pd.DatetimeIndex(univariate_data.index.values, freq = \"MS\")\n",
    "growth_data = 100.0*np.log(univariate_data[['RHP']]).diff().dropna()\n",
    "# Storage for Results & Hyperparameters:\n",
    "Results = pd.DataFrame(columns = ['AR(p)', 'p', 'Train_RMSE', 'Test_RMSE', 'AIC', 'BIC'])\n",
    "# Setting Hyperparameters:\n",
    "AR_Lags = range(1,37,1)\n",
    "MA_Lags = 0\n",
    "Const = 'c'\n",
    "horizons = 1\n",
    "for p in AR_Lags:\n",
    "    try:\n",
    "        train_RMSE, test_RMSE, AIC, BIC = MODEL(growth_data, p = p, q = MA_Lags, trend = Const, step_size = horizons)\n",
    "        model_performance = {'AR(p)':'AR('+str(p)+')', 'p':p, 'Train_RMSE':train_RMSE, 'Test_RMSE':test_RMSE, 'AIC':AIC, 'BIC':BIC}\n",
    "        Results = Results.append(model_performance, ignore_index = True)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516d8d7c",
   "metadata": {},
   "source": [
    "The second block of code reestimates the top performing model after determining the optimal lag length (p).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f5b6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Library:\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Function to Fit Model using Walk Foreward Cross-Validation:\n",
    "def MODEL(data, p = 0, q = 0, step_size = 1, trend = 'n'):\n",
    "    # Extracting Data:\n",
    "    index_values = data.index.values\n",
    "    data = data.values\n",
    "    # Inital Training & Test Set Sizes:\n",
    "    train_size = int(len(data)*0.8)\n",
    "    test_size = len(data)-train_size\n",
    "    # Storage for Growth Forecasts:\n",
    "    test_pred = []\n",
    "    for t in range(test_size-step_size+1):\n",
    "        # Walk Foreward Training Set:\n",
    "        train_set = data[:train_size+t]\n",
    "        # Walk Foreward Test Set:\n",
    "        test_set = data[train_size+t:]\n",
    "        # Tracking Convergence:\n",
    "        print('Test Set Walk Foreward: Iteration '+str(t+1))\n",
    "        # Fit Training Model:\n",
    "        model = SARIMAX(train_set, order = (p,0,q), trend = trend, enforce_stationarity = False, enforce_invertibility = False)\n",
    "        model_fit = model.fit(method = 'bfgs', maxiter = 10000)\n",
    "        # Original Training Model: No Data Leakage\n",
    "        if t == 0:\n",
    "            train_pred = model_fit.predict().reshape((train_size,1))\n",
    "            AIC = model_fit.aic\n",
    "            BIC = model_fit.bic\n",
    "        # N-Step Ahead Forecast:\n",
    "        test_yhat = model_fit.forecast(steps = step_size)\n",
    "        test_pred = np.append(test_pred, test_yhat[step_size-1])\n",
    "    # Model Evaluation:\n",
    "    train_RMSE = np.sqrt(mean_squared_error(data[:train_size], train_pred))\n",
    "    test_RMSE = np.sqrt(mean_squared_error(data[train_size+step_size-1:], test_pred))\n",
    "    # Convert to DataFrame:\n",
    "    train_set = pd.DataFrame(data[:train_size], index = index_values[:train_size], columns = ['train_set'])\n",
    "    train_pred = pd.DataFrame(train_pred, index = index_values[:train_size], columns = ['train_pred'])\n",
    "    test_set = pd.DataFrame(data[train_size+step_size-1:], index = index_values[train_size+step_size-1:], columns = ['test_set'])\n",
    "    test_pred = pd.DataFrame(test_pred, index = index_values[train_size+step_size-1:], columns = ['test_pred'])\n",
    "    return train_size, train_pred, test_pred, train_RMSE, test_RMSE, AIC, BIC\n",
    "# Setting Seed:\n",
    "np.random.seed(12345)\n",
    "# Load in Data & Set Index Frequency: DataFrame \n",
    "univariate_data = read_csv('Univariate_Data.csv', header = 0, index_col = 0, parse_dates = True)\n",
    "univariate_data.index = pd.DatetimeIndex(univariate_data.index.values, freq = \"MS\")\n",
    "growth_data = 100.0*np.log(univariate_data[['RHP']]).diff().dropna()\n",
    "AR_Lags = Results.sort_values(by = 'Test_RMSE', ascending = True).iloc[0,1]\n",
    "MA_Lags = 0\n",
    "Const = 'c'\n",
    "horizons = 1\n",
    "# Evaluate Model: Growth Rate\n",
    "train_size, train_pred, test_pred, train_RMSE, test_RMSE, AIC, BIC = MODEL(growth_data, p = AR_Lags, q = MA_Lags, step_size = horizons, trend = Const)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790f04a5",
   "metadata": {},
   "source": [
    "The third block presents and graphs the stored output from the MODEL function. The MODEL above is fit to housing price data in order to forecast real housing price growth rates at the U.S. national level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b4cb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Autoregressive Model: Growth Rate\n",
    "print('-----------------------------')\n",
    "print('National Housing Price Series')\n",
    "print('-----------------------------')\n",
    "print('Data Type: Growth Rates')\n",
    "print('Model Type: AR('+str(AR_Lags)+')')\n",
    "print('Train RMSE: %.3f' % (train_RMSE))\n",
    "print('Test RMSE: %.3f' % (test_RMSE))\n",
    "print('AIC: %.3f' % (AIC))\n",
    "print('BIC: %.3f' % (BIC))\n",
    "# Plot Forecast: Growth Rate\n",
    "sns.set_theme(style = 'whitegrid')\n",
    "pyplot.figure(figsize = (12,6))\n",
    "pyplot.plot(growth_data, label = 'Observed')\n",
    "pyplot.plot(train_pred['train_pred'], label = 'AR('+str(AR_Lags)+'): Train')\n",
    "pyplot.plot(test_pred['test_pred'], label = 'AR('+str(AR_Lags)+'): Test')\n",
    "pyplot.xlabel('Date')\n",
    "pyplot.ylabel('Growth Rate')\n",
    "pyplot.title('Real Housing Price Series (National)')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9c449a",
   "metadata": {},
   "source": [
    "The fourth block of code is used to analyze the forecast errors for stationarity. The forecast errors are computed, plotted, and distributed. Lastly, the autocorrelation function (ACF) is plotted and the Augmented Dickey-Fuller (ADF) unit root test is carried out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e3b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Library:\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "# Define Residuals:\n",
    "resids = growth_data[:train_size] - train_pred.values\n",
    "# Plot Residuals:\n",
    "sns.set_theme(style = 'whitegrid')\n",
    "pyplot.figure(figsize = (16,4))\n",
    "pyplot.subplot(1,2,1)\n",
    "pyplot.plot(resids)\n",
    "pyplot.xlabel('Date')\n",
    "pyplot.title('Residual Series')\n",
    "pyplot.subplot(1,2,2)\n",
    "pyplot.hist(resids, bins = 20)\n",
    "pyplot.title('Residual Distribution')\n",
    "pyplot.tight_layout()\n",
    "pyplot.show()\n",
    "# Plot Autocorelation Function (ACF):\n",
    "sns.set_theme(style = 'whitegrid')\n",
    "fig, ax = pyplot.subplots(figsize=(8,4))\n",
    "plot_acf(resids, title = 'Residual ACF', lags = 36, ax = ax)\n",
    "pyplot.show()\n",
    "# ADF Test: Non-Stationary v. Stationary\n",
    "ADF_Test = adfuller(resids)\n",
    "print('----------------------')\n",
    "print('  ADF Unit-Root Test  ')\n",
    "print('----------------------')\n",
    "print('Test Statistic: %.3f' % (ADF_Test[0]))\n",
    "print('P-Value: %.3f' % (ADF_Test[1]))\n",
    "print('Critical Values:')\n",
    "for key, value in ADF_Test[4].items():\n",
    "    print('%s: %.3f' % (key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08a5ab0",
   "metadata": {},
   "source": [
    "The last block of code loads in the previous .csv files \"National_Train_Growth_One\" and \"National_Test_Growth_One\" that contain the stored forecasted values. The storage files are then augmented to include the predicted values from the current algorithm in order to estimate the forecast combinations, produce the final \"top performing\" model plots, and carry out the final comparison tests for predictive accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aafda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Forecast Tables: \n",
    "train_forecasts = read_csv('National_Train_Growth_One.csv', header = 0, index_col = 0, parse_dates = True)\n",
    "train_forecasts.index = pd.DatetimeIndex(train_forecasts.index.values, freq = \"MS\")\n",
    "test_forecasts = read_csv('National_Test_Growth_One.csv', header = 0, index_col = 0, parse_dates = True)\n",
    "test_forecasts.index = pd.DatetimeIndex(test_forecasts.index.values, freq = \"MS\")\n",
    "# Add New Forecast Model:\n",
    "train_forecasts['AR'] = train_pred\n",
    "test_forecasts['AR'] = test_pred\n",
    "# Save Forecast:\n",
    "pd.DataFrame(train_forecasts).to_csv('National_Train_Growth_One.csv')\n",
    "pd.DataFrame(test_forecasts).to_csv('National_Test_Growth_One.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
